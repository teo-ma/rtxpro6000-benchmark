/mnt/data/venvs/qwen/lib/python3.12/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
We recommend installing via `pip install torch-c-dlpack-ext`
  warnings.warn(
[2025-12-18 10:39:48] server_args=ServerArgs(model_path='/mnt/data/models', tokenizer_path='/mnt/data/models', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', rl_quant_profile=None, trust_remote_code=True, context_length=10928, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30000, fastapi_root_path='', grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization='fp8', quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.9, max_running_requests=None, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=1, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=933742479, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, mm_process_config={}, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', export_metrics_to_file=False, export_metrics_to_file_dir=None, api_key=None, served_model_name='/mnt/data/models', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=1, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='triton', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, fp8_gemm_runner_backend='cutlass', nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', enable_flashinfer_autotune=False, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_moe_runner_backend=None, speculative_moe_a2a_backend=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm=None, init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_weight_path=None, kt_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, dllm_algorithm=None, dllm_algorithm_config=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=256, cuda_graph_bs=[1, 2, 4, 8, 12, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_layerwise_nvtx_marker=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, enable_piecewise_cuda_graph=False, enable_torch_compile_debug_mode=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, enable_draft_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_attn_tp_input_scattered=False, enable_nsa_prefill_context_parallel=False, enable_fused_qk_norm_rope=False, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, enable_broadcast_mm_inputs_process=False, decrypted_config_file=None, decrypted_draft_config_file=None, mm_enable_dp_encoder=False, forward_hooks=None)
[2025-12-18 10:39:49] Using default HuggingFace chat template with detected content format: string
/mnt/data/venvs/qwen/lib/python3.12/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
We recommend installing via `pip install torch-c-dlpack-ext`
  warnings.warn(
/mnt/data/venvs/qwen/lib/python3.12/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
We recommend installing via `pip install torch-c-dlpack-ext`
  warnings.warn(
[2025-12-18 10:39:56] Init torch distributed begin.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-12-18 10:39:57] Init torch distributed ends. mem usage=0.00 GB
[2025-12-18 10:39:57] MOE_RUNNER_BACKEND is not initialized, the backend will be automatically selected
[2025-12-18 10:39:57] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-18 10:39:58] Load weight begin. avail mem=92.13 GB
[2025-12-18 10:39:58] Detected fp8 checkpoint.
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.41it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.20it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.75it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.54it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.62it/s]

[2025-12-18 10:40:00] Load weight end. type=Qwen3ForCausalLM, dtype=torch.bfloat16, avail mem=76.63 GB, mem usage=15.50 GB.
[2025-12-18 10:40:00] Using KV cache dtype: torch.bfloat16
[2025-12-18 10:40:00] KV Cache is allocated. #tokens: 441817, K size: 33.71 GB, V size: 33.71 GB
[2025-12-18 10:40:00] Memory pool end. avail mem=8.94 GB
[2025-12-18 10:40:00] Capture cuda graph begin. This can take up to several minutes. avail mem=8.93 GB
[2025-12-18 10:40:00] Capture cuda graph bs [1, 2, 4, 8, 12, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256]
  0%|          | 0/36 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=8.72 GB):   0%|          | 0/36 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=8.72 GB):   3%|▎         | 1/36 [00:00<00:18,  1.89it/s]Capturing batches (bs=248 avail_mem=8.55 GB):   3%|▎         | 1/36 [00:00<00:18,  1.89it/s]Capturing batches (bs=240 avail_mem=8.54 GB):   3%|▎         | 1/36 [00:00<00:18,  1.89it/s]Capturing batches (bs=240 avail_mem=8.54 GB):   8%|▊         | 3/36 [00:00<00:06,  5.11it/s]Capturing batches (bs=232 avail_mem=8.54 GB):   8%|▊         | 3/36 [00:00<00:06,  5.11it/s]Capturing batches (bs=224 avail_mem=8.54 GB):   8%|▊         | 3/36 [00:00<00:06,  5.11it/s]Capturing batches (bs=224 avail_mem=8.54 GB):  14%|█▍        | 5/36 [00:00<00:04,  7.44it/s]Capturing batches (bs=216 avail_mem=8.54 GB):  14%|█▍        | 5/36 [00:00<00:04,  7.44it/s]Capturing batches (bs=208 avail_mem=8.53 GB):  14%|█▍        | 5/36 [00:00<00:04,  7.44it/s]Capturing batches (bs=208 avail_mem=8.53 GB):  19%|█▉        | 7/36 [00:00<00:03,  9.18it/s]Capturing batches (bs=200 avail_mem=8.53 GB):  19%|█▉        | 7/36 [00:00<00:03,  9.18it/s]Capturing batches (bs=192 avail_mem=8.53 GB):  19%|█▉        | 7/36 [00:01<00:03,  9.18it/s]Capturing batches (bs=192 avail_mem=8.53 GB):  25%|██▌       | 9/36 [00:01<00:02,  9.85it/s]Capturing batches (bs=184 avail_mem=8.53 GB):  25%|██▌       | 9/36 [00:01<00:02,  9.85it/s]Capturing batches (bs=176 avail_mem=8.53 GB):  25%|██▌       | 9/36 [00:01<00:02,  9.85it/s]Capturing batches (bs=176 avail_mem=8.53 GB):  31%|███       | 11/36 [00:01<00:02, 10.76it/s]Capturing batches (bs=168 avail_mem=8.52 GB):  31%|███       | 11/36 [00:01<00:02, 10.76it/s]Capturing batches (bs=160 avail_mem=8.52 GB):  31%|███       | 11/36 [00:01<00:02, 10.76it/s]Capturing batches (bs=160 avail_mem=8.52 GB):  36%|███▌      | 13/36 [00:01<00:02, 11.45it/s]Capturing batches (bs=152 avail_mem=8.52 GB):  36%|███▌      | 13/36 [00:01<00:02, 11.45it/s]Capturing batches (bs=144 avail_mem=8.51 GB):  36%|███▌      | 13/36 [00:01<00:02, 11.45it/s]Capturing batches (bs=144 avail_mem=8.51 GB):  42%|████▏     | 15/36 [00:01<00:01, 11.74it/s]Capturing batches (bs=136 avail_mem=8.51 GB):  42%|████▏     | 15/36 [00:01<00:01, 11.74it/s]Capturing batches (bs=128 avail_mem=8.51 GB):  42%|████▏     | 15/36 [00:01<00:01, 11.74it/s]Capturing batches (bs=128 avail_mem=8.51 GB):  47%|████▋     | 17/36 [00:01<00:01, 12.20it/s]Capturing batches (bs=120 avail_mem=8.50 GB):  47%|████▋     | 17/36 [00:01<00:01, 12.20it/s]Capturing batches (bs=112 avail_mem=8.50 GB):  47%|████▋     | 17/36 [00:01<00:01, 12.20it/s]Capturing batches (bs=112 avail_mem=8.50 GB):  53%|█████▎    | 19/36 [00:01<00:01, 12.56it/s]Capturing batches (bs=104 avail_mem=8.50 GB):  53%|█████▎    | 19/36 [00:01<00:01, 12.56it/s]Capturing batches (bs=96 avail_mem=8.50 GB):  53%|█████▎    | 19/36 [00:02<00:01, 12.56it/s] Capturing batches (bs=96 avail_mem=8.50 GB):  58%|█████▊    | 21/36 [00:02<00:01, 12.70it/s]Capturing batches (bs=88 avail_mem=8.49 GB):  58%|█████▊    | 21/36 [00:02<00:01, 12.70it/s]Capturing batches (bs=80 avail_mem=8.49 GB):  58%|█████▊    | 21/36 [00:02<00:01, 12.70it/s]Capturing batches (bs=80 avail_mem=8.49 GB):  64%|██████▍   | 23/36 [00:02<00:01, 12.19it/s]Capturing batches (bs=72 avail_mem=8.48 GB):  64%|██████▍   | 23/36 [00:02<00:01, 12.19it/s]Capturing batches (bs=64 avail_mem=8.48 GB):  64%|██████▍   | 23/36 [00:02<00:01, 12.19it/s]Capturing batches (bs=64 avail_mem=8.48 GB):  69%|██████▉   | 25/36 [00:02<00:00, 12.51it/s]Capturing batches (bs=56 avail_mem=8.48 GB):  69%|██████▉   | 25/36 [00:02<00:00, 12.51it/s]Capturing batches (bs=48 avail_mem=8.47 GB):  69%|██████▉   | 25/36 [00:02<00:00, 12.51it/s]Capturing batches (bs=48 avail_mem=8.47 GB):  75%|███████▌  | 27/36 [00:02<00:00, 12.71it/s]Capturing batches (bs=40 avail_mem=8.47 GB):  75%|███████▌  | 27/36 [00:02<00:00, 12.71it/s]Capturing batches (bs=32 avail_mem=8.47 GB):  75%|███████▌  | 27/36 [00:02<00:00, 12.71it/s]Capturing batches (bs=32 avail_mem=8.47 GB):  81%|████████  | 29/36 [00:02<00:00, 12.74it/s]Capturing batches (bs=24 avail_mem=8.47 GB):  81%|████████  | 29/36 [00:02<00:00, 12.74it/s]Capturing batches (bs=16 avail_mem=8.46 GB):  81%|████████  | 29/36 [00:02<00:00, 12.74it/s]Capturing batches (bs=16 avail_mem=8.46 GB):  86%|████████▌ | 31/36 [00:02<00:00, 12.04it/s]Capturing batches (bs=12 avail_mem=8.46 GB):  86%|████████▌ | 31/36 [00:02<00:00, 12.04it/s]Capturing batches (bs=8 avail_mem=8.46 GB):  86%|████████▌ | 31/36 [00:02<00:00, 12.04it/s] Capturing batches (bs=8 avail_mem=8.46 GB):  92%|█████████▏| 33/36 [00:03<00:00, 12.53it/s]Capturing batches (bs=4 avail_mem=8.46 GB):  92%|█████████▏| 33/36 [00:03<00:00, 12.53it/s]Capturing batches (bs=2 avail_mem=8.46 GB):  92%|█████████▏| 33/36 [00:03<00:00, 12.53it/s]Capturing batches (bs=2 avail_mem=8.46 GB):  97%|█████████▋| 35/36 [00:03<00:00, 12.17it/s]Capturing batches (bs=1 avail_mem=8.44 GB):  97%|█████████▋| 35/36 [00:03<00:00, 12.17it/s]Capturing batches (bs=1 avail_mem=8.44 GB): 100%|██████████| 36/36 [00:03<00:00, 10.76it/s]
[2025-12-18 10:40:04] Capture cuda graph end. Time elapsed: 3.74 s. mem usage=0.49 GB. avail mem=8.44 GB.
[2025-12-18 10:40:04] max_total_num_tokens=441817, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4096, context_len=10928, available_gpu_mem=8.44 GB
[2025-12-18 10:40:05] INFO:     Started server process [75848]
[2025-12-18 10:40:05] INFO:     Waiting for application startup.
[2025-12-18 10:40:05] Using default chat sampling params from model generation config: {'repetition_penalty': 1.0, 'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[2025-12-18 10:40:05] Using default chat sampling params from model generation config: {'repetition_penalty': 1.0, 'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[2025-12-18 10:40:05] INFO:     Application startup complete.
[2025-12-18 10:40:05] INFO:     Uvicorn running on http://0.0.0.0:30000 (Press CTRL+C to quit)
[2025-12-18 10:40:05] INFO:     127.0.0.1:46678 - "GET /v1/models HTTP/1.1" 200 OK
[2025-12-18 10:40:06] Endpoint '/get_model_info' is deprecated and will be removed in a future version. Please use '/model_info' instead.
[2025-12-18 10:40:06] INFO:     127.0.0.1:46694 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-12-18 10:40:06] Prefill batch, #new-seq: 1, #new-token: 6, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-18 10:40:08] INFO:     127.0.0.1:46704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:08] The server is fired up and ready to roll!
[2025-12-18 10:40:09] INFO:     127.0.0.1:46708 - "GET /v1/models HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] Prefill batch, #new-seq: 1, #new-token: 236, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-18 10:40:16] INFO:     127.0.0.1:48402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-12-18 10:40:16] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:16] INFO:     127.0.0.1:48460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:17] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.02, #running-req: 3, #queue-req: 3, 
[2025-12-18 10:40:17] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 1, token usage: 0.04, #running-req: 4, #queue-req: 2, 
[2025-12-18 10:40:18] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.06, #running-req: 7, #queue-req: 1, 
[2025-12-18 10:40:18] Prefill batch, #new-seq: 2, #new-token: 4767, #cached-token: 0, token usage: 0.07, #running-req: 8, #queue-req: 0, 
[2025-12-18 10:40:20] Decode batch, #running-req: 10, #token: 38102, token usage: 0.09, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-18 10:40:21] Decode batch, #running-req: 10, #token: 38502, token usage: 0.09, cuda graph: True, gen throughput (token/s): 421.51, #queue-req: 0, 
[2025-12-18 10:40:22] Decode batch, #running-req: 10, #token: 38902, token usage: 0.09, cuda graph: True, gen throughput (token/s): 420.69, #queue-req: 0, 
[2025-12-18 10:40:23] Decode batch, #running-req: 10, #token: 39302, token usage: 0.09, cuda graph: True, gen throughput (token/s): 420.13, #queue-req: 0, 
[2025-12-18 10:40:24] Decode batch, #running-req: 9, #token: 34316, token usage: 0.08, cuda graph: True, gen throughput (token/s): 408.11, #queue-req: 0, 
[2025-12-18 10:40:25] Decode batch, #running-req: 9, #token: 34676, token usage: 0.08, cuda graph: True, gen throughput (token/s): 383.56, #queue-req: 0, 
[2025-12-18 10:40:26] Decode batch, #running-req: 7, #token: 26447, token usage: 0.06, cuda graph: True, gen throughput (token/s): 349.65, #queue-req: 0, 
[2025-12-18 10:40:27] Decode batch, #running-req: 5, #token: 24959, token usage: 0.06, cuda graph: True, gen throughput (token/s): 237.18, #queue-req: 0, 
[2025-12-18 10:40:28] Decode batch, #running-req: 5, #token: 25159, token usage: 0.06, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-18 10:40:29] Decode batch, #running-req: 4, #token: 22070, token usage: 0.05, cuda graph: True, gen throughput (token/s): 183.31, #queue-req: 0, 
[2025-12-18 10:40:29] Decode batch, #running-req: 3, #token: 18334, token usage: 0.04, cuda graph: True, gen throughput (token/s): 140.94, #queue-req: 0, 
[2025-12-18 10:40:30] Decode batch, #running-req: 2, #token: 12924, token usage: 0.03, cuda graph: True, gen throughput (token/s): 129.04, #queue-req: 0, 
[2025-12-18 10:40:31] Decode batch, #running-req: 1, #token: 8265, token usage: 0.02, cuda graph: True, gen throughput (token/s): 62.22, #queue-req: 0, 
[2025-12-18 10:40:32] Decode batch, #running-req: 1, #token: 8305, token usage: 0.02, cuda graph: True, gen throughput (token/s): 41.92, #queue-req: 0, 
[2025-12-18 10:40:33] Decode batch, #running-req: 1, #token: 8345, token usage: 0.02, cuda graph: True, gen throughput (token/s): 41.90, #queue-req: 0, 
[2025-12-18 10:40:34] Decode batch, #running-req: 1, #token: 8385, token usage: 0.02, cuda graph: True, gen throughput (token/s): 41.92, #queue-req: 0, 
[2025-12-18 10:40:35] Endpoint '/get_server_info' is deprecated and will be removed in a future version. Please use '/server_info' instead.
[2025-12-18 10:40:35] INFO:     127.0.0.1:60466 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-12-18 10:40:35] Endpoint '/get_server_info' is deprecated and will be removed in a future version. Please use '/server_info' instead.
[2025-12-18 10:40:35] INFO:     127.0.0.1:60470 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-12-18 10:40:39] INFO:     127.0.0.1:60480 - "GET /v1/models HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 235, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-18 10:40:45] INFO:     127.0.0.1:33264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] Prefill batch, #new-seq: 3, #new-token: 3, #cached-token: 13994, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-12-18 10:40:45] INFO:     127.0.0.1:33284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33330 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33574 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] INFO:     127.0.0.1:33594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:40:45] Prefill batch, #new-seq: 7, #new-token: 8192, #cached-token: 23533, token usage: 0.09, #running-req: 4, #queue-req: 29, 
[2025-12-18 10:40:46] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.10, #running-req: 10, #queue-req: 27, 
[2025-12-18 10:40:47] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.12, #running-req: 12, #queue-req: 25, 
[2025-12-18 10:40:48] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.14, #running-req: 14, #queue-req: 24, 
[2025-12-18 10:40:48] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 1, token usage: 0.16, #running-req: 15, #queue-req: 22, 
[2025-12-18 10:40:49] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.18, #running-req: 17, #queue-req: 21, 
[2025-12-18 10:40:49] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.20, #running-req: 18, #queue-req: 20, 
[2025-12-18 10:40:50] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 2, token usage: 0.22, #running-req: 19, #queue-req: 18, 
[2025-12-18 10:40:50] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 0, token usage: 0.23, #running-req: 21, #queue-req: 15, 
[2025-12-18 10:40:51] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 1, token usage: 0.25, #running-req: 24, #queue-req: 13, 
[2025-12-18 10:40:52] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 2, token usage: 0.27, #running-req: 26, #queue-req: 11, 
[2025-12-18 10:40:52] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.29, #running-req: 28, #queue-req: 9, 
[2025-12-18 10:40:53] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 2, token usage: 0.31, #running-req: 30, #queue-req: 7, 
[2025-12-18 10:40:53] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.33, #running-req: 32, #queue-req: 6, 
[2025-12-18 10:40:54] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.35, #running-req: 33, #queue-req: 4, 
[2025-12-18 10:40:55] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.36, #running-req: 35, #queue-req: 3, 
[2025-12-18 10:40:55] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 3, token usage: 0.38, #running-req: 36, #queue-req: 0, 
[2025-12-18 10:40:56] Prefill batch, #new-seq: 1, #new-token: 515, #cached-token: 0, token usage: 0.40, #running-req: 39, #queue-req: 0, 
[2025-12-18 10:40:56] Decode batch, #running-req: 40, #token: 177705, token usage: 0.40, cuda graph: True, gen throughput (token/s): 7.02, #queue-req: 0, 
[2025-12-18 10:40:58] Decode batch, #running-req: 36, #token: 143519, token usage: 0.32, cuda graph: True, gen throughput (token/s): 1075.08, #queue-req: 0, 
[2025-12-18 10:40:59] Decode batch, #running-req: 33, #token: 140806, token usage: 0.32, cuda graph: True, gen throughput (token/s): 1029.37, #queue-req: 0, 
[2025-12-18 10:41:01] Decode batch, #running-req: 33, #token: 142126, token usage: 0.32, cuda graph: True, gen throughput (token/s): 993.03, #queue-req: 0, 
[2025-12-18 10:41:02] Decode batch, #running-req: 31, #token: 133390, token usage: 0.30, cuda graph: True, gen throughput (token/s): 915.45, #queue-req: 0, 
[2025-12-18 10:41:03] Decode batch, #running-req: 29, #token: 120537, token usage: 0.27, cuda graph: True, gen throughput (token/s): 940.24, #queue-req: 0, 
[2025-12-18 10:41:04] Decode batch, #running-req: 29, #token: 121697, token usage: 0.28, cuda graph: True, gen throughput (token/s): 914.94, #queue-req: 0, 
[2025-12-18 10:41:06] Decode batch, #running-req: 28, #token: 118208, token usage: 0.27, cuda graph: True, gen throughput (token/s): 908.83, #queue-req: 0, 
[2025-12-18 10:41:07] Decode batch, #running-req: 23, #token: 102102, token usage: 0.23, cuda graph: True, gen throughput (token/s): 806.98, #queue-req: 0, 
[2025-12-18 10:41:08] Decode batch, #running-req: 21, #token: 94036, token usage: 0.21, cuda graph: True, gen throughput (token/s): 766.22, #queue-req: 0, 
[2025-12-18 10:41:09] Decode batch, #running-req: 18, #token: 77018, token usage: 0.17, cuda graph: True, gen throughput (token/s): 701.83, #queue-req: 0, 
[2025-12-18 10:41:10] Decode batch, #running-req: 17, #token: 73219, token usage: 0.17, cuda graph: True, gen throughput (token/s): 656.52, #queue-req: 0, 
[2025-12-18 10:41:11] Decode batch, #running-req: 14, #token: 60872, token usage: 0.14, cuda graph: True, gen throughput (token/s): 597.48, #queue-req: 0, 
[2025-12-18 10:41:12] Decode batch, #running-req: 12, #token: 51102, token usage: 0.12, cuda graph: True, gen throughput (token/s): 524.03, #queue-req: 0, 
[2025-12-18 10:41:13] Decode batch, #running-req: 11, #token: 43120, token usage: 0.10, cuda graph: True, gen throughput (token/s): 479.40, #queue-req: 0, 
[2025-12-18 10:41:14] Decode batch, #running-req: 9, #token: 36336, token usage: 0.08, cuda graph: True, gen throughput (token/s): 429.56, #queue-req: 0, 
[2025-12-18 10:41:15] Decode batch, #running-req: 7, #token: 20622, token usage: 0.05, cuda graph: True, gen throughput (token/s): 344.37, #queue-req: 0, 
[2025-12-18 10:41:16] Decode batch, #running-req: 5, #token: 12040, token usage: 0.03, cuda graph: True, gen throughput (token/s): 264.21, #queue-req: 0, 
[2025-12-18 10:41:17] Decode batch, #running-req: 4, #token: 5258, token usage: 0.01, cuda graph: True, gen throughput (token/s): 222.25, #queue-req: 0, 
[2025-12-18 10:41:18] Decode batch, #running-req: 3, #token: 4091, token usage: 0.01, cuda graph: True, gen throughput (token/s): 173.94, #queue-req: 0, 
[2025-12-18 10:41:18] Endpoint '/get_server_info' is deprecated and will be removed in a future version. Please use '/server_info' instead.
[2025-12-18 10:41:18] INFO:     127.0.0.1:41956 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-12-18 10:41:18] Endpoint '/get_server_info' is deprecated and will be removed in a future version. Please use '/server_info' instead.
[2025-12-18 10:41:18] INFO:     127.0.0.1:41960 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-12-18 10:41:23] INFO:     127.0.0.1:46758 - "GET /v1/models HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 235, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:46786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 4, #new-token: 4, #cached-token: 16889, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:46808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 3, #new-token: 3, #cached-token: 9425, token usage: 0.06, #running-req: 5, #queue-req: 0, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:46826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 6, #new-token: 6, #cached-token: 34311, token usage: 0.14, #running-req: 8, #queue-req: 0, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:46878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46884 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46900 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 5, #new-token: 5, #cached-token: 27527, token usage: 0.20, #running-req: 14, #queue-req: 0, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:46906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 9, #new-token: 9, #cached-token: 38232, token usage: 0.29, #running-req: 19, #queue-req: 0, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:46992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:46994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 7, #new-token: 7, #cached-token: 30085, token usage: 0.35, #running-req: 28, #queue-req: 0, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:47056 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47070 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 6, #new-token: 8192, #cached-token: 20812, token usage: 0.40, #running-req: 35, #queue-req: 3, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:47132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 3, token usage: 0.42, #running-req: 40, #queue-req: 5, 
[2025-12-18 10:41:29] INFO:     127.0.0.1:47210 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47400 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:29] INFO:     127.0.0.1:47642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47880 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:47992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48286 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48400 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] INFO:     127.0.0.1:48562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-18 10:41:30] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.44, #running-req: 43, #queue-req: 155, 
[2025-12-18 10:41:31] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 3, token usage: 0.46, #running-req: 44, #queue-req: 152, 
[2025-12-18 10:41:32] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 1, token usage: 0.48, #running-req: 47, #queue-req: 151, 
[2025-12-18 10:41:32] Prefill batch, #new-seq: 5, #new-token: 8192, #cached-token: 2, token usage: 0.49, #running-req: 48, #queue-req: 147, 
[2025-12-18 10:41:33] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 1, token usage: 0.51, #running-req: 52, #queue-req: 146, 
[2025-12-18 10:41:33] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.53, #running-req: 53, #queue-req: 145, 
[2025-12-18 10:41:34] Prefill batch, #new-seq: 4, #new-token: 7601, #cached-token: 2, token usage: 0.55, #running-req: 54, #queue-req: 142, 
[2025-12-18 10:41:35] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.57, #running-req: 58, #queue-req: 141, 
[2025-12-18 10:41:35] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 3, token usage: 0.59, #running-req: 58, #queue-req: 138, 
[2025-12-18 10:41:35] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.60, #running-req: 61, #queue-req: 136, 
[2025-12-18 10:41:36] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 3, token usage: 0.62, #running-req: 63, #queue-req: 135, 
[2025-12-18 10:41:37] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 2, token usage: 0.64, #running-req: 64, #queue-req: 133, 
[2025-12-18 10:41:37] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.66, #running-req: 66, #queue-req: 132, 
[2025-12-18 10:41:38] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 4, token usage: 0.68, #running-req: 67, #queue-req: 129, 
[2025-12-18 10:41:38] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.70, #running-req: 70, #queue-req: 127, 
[2025-12-18 10:41:39] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 3, token usage: 0.72, #running-req: 72, #queue-req: 125, 
[2025-12-18 10:41:40] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 1, token usage: 0.73, #running-req: 74, #queue-req: 124, 
[2025-12-18 10:41:40] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.75, #running-req: 75, #queue-req: 122, 
[2025-12-18 10:41:41] Prefill batch, #new-seq: 1, #new-token: 6827, #cached-token: 0, token usage: 0.77, #running-req: 77, #queue-req: 122, 
[2025-12-18 10:41:42] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 2, token usage: 0.79, #running-req: 78, #queue-req: 121, 
[2025-12-18 10:41:42] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 1, token usage: 0.81, #running-req: 78, #queue-req: 119, 
[2025-12-18 10:41:42] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 8, token usage: 0.82, #running-req: 80, #queue-req: 116, 
[2025-12-18 10:41:43] Prefill batch, #new-seq: 5, #new-token: 8192, #cached-token: 5, token usage: 0.84, #running-req: 83, #queue-req: 112, 
[2025-12-18 10:41:44] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 2, token usage: 0.86, #running-req: 87, #queue-req: 111, 
[2025-12-18 10:41:44] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 0, token usage: 0.88, #running-req: 88, #queue-req: 109, 
[2025-12-18 10:41:45] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.90, #running-req: 90, #queue-req: 108, 
[2025-12-18 10:41:45] Prefill batch, #new-seq: 2, #new-token: 3106, #cached-token: 1, token usage: 0.92, #running-req: 91, #queue-req: 107, 
[2025-12-18 10:41:47] Decode batch, #running-req: 93, #token: 409088, token usage: 0.93, cuda graph: True, gen throughput (token/s): 34.40, #queue-req: 107, 
[2025-12-18 10:41:48] Prefill batch, #new-seq: 1, #new-token: 7710, #cached-token: 1, token usage: 0.92, #running-req: 92, #queue-req: 106, 
[2025-12-18 10:41:50] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.92, #running-req: 91, #queue-req: 105, 
[2025-12-18 10:41:50] Decode batch, #running-req: 91, #token: 413058, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1215.76, #queue-req: 105, 
[2025-12-18 10:41:50] Prefill batch, #new-seq: 1, #new-token: 1573, #cached-token: 0, token usage: 0.93, #running-req: 91, #queue-req: 105, 
[2025-12-18 10:41:50] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 3, token usage: 0.92, #running-req: 91, #queue-req: 104, 
[2025-12-18 10:41:50] Prefill batch, #new-seq: 1, #new-token: 1780, #cached-token: 0, token usage: 0.94, #running-req: 91, #queue-req: 104, 
[2025-12-18 10:41:53] Prefill batch, #new-seq: 1, #new-token: 3884, #cached-token: 2, token usage: 0.93, #running-req: 91, #queue-req: 103, 
[2025-12-18 10:41:54] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 3, token usage: 0.92, #running-req: 91, #queue-req: 101, 
[2025-12-18 10:41:54] Prefill batch, #new-seq: 2, #new-token: 6293, #cached-token: 0, token usage: 0.94, #running-req: 92, #queue-req: 100, 
[2025-12-18 10:41:55] Decode batch, #running-req: 94, #token: 419727, token usage: 0.95, cuda graph: True, gen throughput (token/s): 715.12, #queue-req: 100, 
[2025-12-18 10:41:57] Decode batch, #running-req: 92, #token: 423301, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1433.03, #queue-req: 100, 
[2025-12-18 10:41:57] Prefill batch, #new-seq: 4, #new-token: 7708, #cached-token: 7, token usage: 0.92, #running-req: 91, #queue-req: 96, 
[2025-12-18 10:41:58] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.93, #running-req: 93, #queue-req: 95, 
[2025-12-18 10:41:58] Prefill batch, #new-seq: 1, #new-token: 1636, #cached-token: 0, token usage: 0.95, #running-req: 93, #queue-req: 95, 
[2025-12-18 10:41:59] Prefill batch, #new-seq: 1, #new-token: 3213, #cached-token: 0, token usage: 0.94, #running-req: 93, #queue-req: 94, 
[2025-12-18 10:42:00] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.94, #running-req: 93, #queue-req: 93, 
[2025-12-18 10:42:00] Prefill batch, #new-seq: 1, #new-token: 607, #cached-token: 0, token usage: 0.96, #running-req: 93, #queue-req: 93, 
[2025-12-18 10:42:02] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.93, #running-req: 92, #queue-req: 91, 
[2025-12-18 10:42:02] Prefill batch, #new-seq: 3, #new-token: 3566, #cached-token: 6, token usage: 0.95, #running-req: 93, #queue-req: 89, 
[2025-12-18 10:42:02] Prefill batch, #new-seq: 2, #new-token: 7154, #cached-token: 1, token usage: 0.94, #running-req: 95, #queue-req: 87, 
[2025-12-18 10:42:03] Decode batch, #running-req: 96, #token: 423066, token usage: 0.96, cuda graph: True, gen throughput (token/s): 647.01, #queue-req: 87, 
[2025-12-18 10:42:03] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 5, token usage: 0.93, #running-req: 94, #queue-req: 86, 
[2025-12-18 10:42:04] Prefill batch, #new-seq: 1, #new-token: 1752, #cached-token: 0, token usage: 0.95, #running-req: 94, #queue-req: 86, 
[2025-12-18 10:42:05] Prefill batch, #new-seq: 1, #new-token: 7815, #cached-token: 2, token usage: 0.94, #running-req: 93, #queue-req: 85, 
[2025-12-18 10:42:07] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 2, token usage: 0.94, #running-req: 93, #queue-req: 83, 
[2025-12-18 10:42:07] Prefill batch, #new-seq: 1, #new-token: 310, #cached-token: 0, token usage: 0.96, #running-req: 94, #queue-req: 83, 
[2025-12-18 10:42:07] Decode batch, #running-req: 94, #token: 422243, token usage: 0.96, cuda graph: True, gen throughput (token/s): 862.57, #queue-req: 83, 
[2025-12-18 10:42:07] Prefill batch, #new-seq: 1, #new-token: 3271, #cached-token: 0, token usage: 0.96, #running-req: 93, #queue-req: 82, 
[2025-12-18 10:42:09] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 1, token usage: 0.93, #running-req: 93, #queue-req: 81, 
[2025-12-18 10:42:09] Prefill batch, #new-seq: 3, #new-token: 7499, #cached-token: 1, token usage: 0.94, #running-req: 93, #queue-req: 79, 
[2025-12-18 10:42:11] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.95, #running-req: 92, #queue-req: 77, 
[2025-12-18 10:42:11] Prefill batch, #new-seq: 1, #new-token: 528, #cached-token: 0, token usage: 0.97, #running-req: 93, #queue-req: 77, 
[2025-12-18 10:42:12] Decode batch, #running-req: 94, #token: 428354, token usage: 0.97, cuda graph: True, gen throughput (token/s): 805.04, #queue-req: 77, 
[2025-12-18 10:42:13] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 3, token usage: 0.93, #running-req: 92, #queue-req: 75, 
[2025-12-18 10:42:13] Prefill batch, #new-seq: 1, #new-token: 4698, #cached-token: 0, token usage: 0.95, #running-req: 93, #queue-req: 75, 
[2025-12-18 10:42:14] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 4, token usage: 0.93, #running-req: 93, #queue-req: 71, 
[2025-12-18 10:42:14] Prefill batch, #new-seq: 2, #new-token: 6116, #cached-token: 0, token usage: 0.95, #running-req: 96, #queue-req: 70, 
[2025-12-18 10:42:15] Prefill batch, #new-seq: 1, #new-token: 3083, #cached-token: 0, token usage: 0.96, #running-req: 97, #queue-req: 69, 
[2025-12-18 10:42:16] Prefill batch, #new-seq: 2, #new-token: 7445, #cached-token: 2, token usage: 0.95, #running-req: 96, #queue-req: 67, 
[2025-12-18 10:42:17] Decode batch, #running-req: 98, #token: 426859, token usage: 0.97, cuda graph: True, gen throughput (token/s): 767.63, #queue-req: 67, 
[2025-12-18 10:42:18] Prefill batch, #new-seq: 1, #new-token: 6460, #cached-token: 2, token usage: 0.95, #running-req: 97, #queue-req: 66, 
[2025-12-18 10:42:18] Prefill batch, #new-seq: 1, #new-token: 3640, #cached-token: 1, token usage: 0.96, #running-req: 97, #queue-req: 65, 
[2025-12-18 10:42:20] Prefill batch, #new-seq: 1, #new-token: 7896, #cached-token: 2, token usage: 0.94, #running-req: 95, #queue-req: 64, 
[2025-12-18 10:42:21] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.95, #running-req: 95, #queue-req: 63, 
[2025-12-18 10:42:21] Prefill batch, #new-seq: 2, #new-token: 3696, #cached-token: 0, token usage: 0.97, #running-req: 95, #queue-req: 62, 
[2025-12-18 10:42:22] Decode batch, #running-req: 97, #token: 430991, token usage: 0.98, cuda graph: True, gen throughput (token/s): 846.52, #queue-req: 62, 
[2025-12-18 10:42:22] Prefill batch, #new-seq: 2, #new-token: 7768, #cached-token: 3, token usage: 0.95, #running-req: 96, #queue-req: 60, 
[2025-12-18 10:42:24] Prefill batch, #new-seq: 1, #new-token: 8130, #cached-token: 2, token usage: 0.95, #running-req: 96, #queue-req: 59, 
[2025-12-18 10:42:25] Decode batch, #running-req: 97, #token: 421503, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1056.09, #queue-req: 59, 
[2025-12-18 10:42:26] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 1, token usage: 0.95, #running-req: 96, #queue-req: 57, 
[2025-12-18 10:42:26] Prefill batch, #new-seq: 1, #new-token: 2562, #cached-token: 0, token usage: 0.97, #running-req: 97, #queue-req: 57, 
[2025-12-18 10:42:27] Prefill batch, #new-seq: 2, #new-token: 7186, #cached-token: 3, token usage: 0.96, #running-req: 95, #queue-req: 55, 
[2025-12-18 10:42:28] Prefill batch, #new-seq: 1, #new-token: 7781, #cached-token: 1, token usage: 0.96, #running-req: 96, #queue-req: 54, 
[2025-12-18 10:42:30] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 1, token usage: 0.95, #running-req: 95, #queue-req: 53, 
[2025-12-18 10:42:30] Prefill batch, #new-seq: 5, #new-token: 8192, #cached-token: 3, token usage: 0.95, #running-req: 95, #queue-req: 49, 
[2025-12-18 10:42:30] Prefill batch, #new-seq: 1, #new-token: 695, #cached-token: 0, token usage: 0.97, #running-req: 99, #queue-req: 49, 
[2025-12-18 10:42:31] Decode batch, #running-req: 99, #token: 429279, token usage: 0.97, cuda graph: True, gen throughput (token/s): 699.99, #queue-req: 49, 
[2025-12-18 10:42:31] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 1, token usage: 0.95, #running-req: 97, #queue-req: 47, 
[2025-12-18 10:42:32] Prefill batch, #new-seq: 1, #new-token: 6056, #cached-token: 0, token usage: 0.97, #running-req: 98, #queue-req: 47, 
[2025-12-18 10:42:34] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 1, token usage: 0.96, #running-req: 95, #queue-req: 45, 
[2025-12-18 10:42:34] Prefill batch, #new-seq: 3, #new-token: 5393, #cached-token: 4, token usage: 0.97, #running-req: 96, #queue-req: 43, 
[2025-12-18 10:42:35] Decode batch, #running-req: 97, #token: 434265, token usage: 0.98, cuda graph: True, gen throughput (token/s): 873.83, #queue-req: 43, 
[2025-12-18 10:42:36] Prefill batch, #new-seq: 1, #new-token: 6166, #cached-token: 0, token usage: 0.97, #running-req: 94, #queue-req: 42, 
[2025-12-18 10:42:37] Prefill batch, #new-seq: 2, #new-token: 4850, #cached-token: 3, token usage: 0.97, #running-req: 94, #queue-req: 40, 
[2025-12-18 10:42:38] Prefill batch, #new-seq: 2, #new-token: 6898, #cached-token: 1, token usage: 0.97, #running-req: 93, #queue-req: 38, 
[2025-12-18 10:42:39] Prefill batch, #new-seq: 1, #new-token: 5539, #cached-token: 0, token usage: 0.97, #running-req: 94, #queue-req: 37, 
[2025-12-18 10:42:40] Decode batch, #running-req: 95, #token: 435134, token usage: 0.98, cuda graph: True, gen throughput (token/s): 921.14, #queue-req: 37, 
[2025-12-18 10:42:41] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 3, token usage: 0.94, #running-req: 90, #queue-req: 35, 
[2025-12-18 10:42:41] Prefill batch, #new-seq: 3, #new-token: 8192, #cached-token: 2, token usage: 0.96, #running-req: 91, #queue-req: 33, 
[2025-12-18 10:42:41] Prefill batch, #new-seq: 1, #new-token: 3913, #cached-token: 0, token usage: 0.97, #running-req: 93, #queue-req: 33, 
[2025-12-18 10:42:43] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 2, token usage: 0.95, #running-req: 90, #queue-req: 32, 
[2025-12-18 10:42:43] Prefill batch, #new-seq: 4, #new-token: 8192, #cached-token: 3, token usage: 0.95, #running-req: 90, #queue-req: 29, 
[2025-12-18 10:42:44] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.96, #running-req: 93, #queue-req: 28, 
[2025-12-18 10:42:44] Prefill batch, #new-seq: 1, #new-token: 608, #cached-token: 0, token usage: 0.98, #running-req: 94, #queue-req: 28, 
[2025-12-18 10:42:45] Prefill batch, #new-seq: 1, #new-token: 7455, #cached-token: 2, token usage: 0.97, #running-req: 92, #queue-req: 27, 
[2025-12-18 10:42:46] Decode batch, #running-req: 93, #token: 432016, token usage: 0.98, cuda graph: True, gen throughput (token/s): 591.98, #queue-req: 27, 
[2025-12-18 10:42:48] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.96, #running-req: 89, #queue-req: 26, 
[2025-12-18 10:42:48] Prefill batch, #new-seq: 4, #new-token: 3279, #cached-token: 5, token usage: 0.98, #running-req: 89, #queue-req: 23, 
[2025-12-18 10:42:49] Decode batch, #running-req: 92, #token: 432002, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1067.51, #queue-req: 23, 
[2025-12-18 10:42:50] Prefill batch, #new-seq: 2, #new-token: 7602, #cached-token: 7, token usage: 0.97, #running-req: 91, #queue-req: 21, 
[2025-12-18 10:42:52] Prefill batch, #new-seq: 1, #new-token: 5698, #cached-token: 1, token usage: 0.98, #running-req: 90, #queue-req: 20, 
[2025-12-18 10:42:53] Decode batch, #running-req: 89, #token: 434311, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1032.74, #queue-req: 20, 
[2025-12-18 10:42:53] Prefill batch, #new-seq: 2, #new-token: 6289, #cached-token: 0, token usage: 0.97, #running-req: 87, #queue-req: 18, 
[2025-12-18 10:42:54] Prefill batch, #new-seq: 2, #new-token: 8170, #cached-token: 1, token usage: 0.96, #running-req: 86, #queue-req: 16, 
[2025-12-18 10:42:55] Prefill batch, #new-seq: 1, #new-token: 7789, #cached-token: 0, token usage: 0.97, #running-req: 87, #queue-req: 15, 
[2025-12-18 10:42:56] Prefill batch, #new-seq: 1, #new-token: 5326, #cached-token: 6, token usage: 0.97, #running-req: 87, #queue-req: 14, 
[2025-12-18 10:42:56] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.96, #running-req: 87, #queue-req: 13, 
[2025-12-18 10:42:56] Prefill batch, #new-seq: 2, #new-token: 8020, #cached-token: 1, token usage: 0.97, #running-req: 87, #queue-req: 12, 
[2025-12-18 10:42:58] Prefill batch, #new-seq: 1, #new-token: 2037, #cached-token: 0, token usage: 0.98, #running-req: 87, #queue-req: 11, 
[2025-12-18 10:42:58] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 1, token usage: 0.97, #running-req: 87, #queue-req: 10, 
[2025-12-18 10:42:58] Prefill batch, #new-seq: 2, #new-token: 2577, #cached-token: 1, token usage: 0.98, #running-req: 87, #queue-req: 9, 
[2025-12-18 10:42:59] Decode batch, #running-req: 88, #token: 430874, token usage: 0.98, cuda graph: True, gen throughput (token/s): 532.39, #queue-req: 9, 
[2025-12-18 10:43:00] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 1, token usage: 0.95, #running-req: 87, #queue-req: 8, 
[2025-12-18 10:43:00] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 0, token usage: 0.97, #running-req: 87, #queue-req: 7, 
[2025-12-18 10:43:00] Prefill batch, #new-seq: 1, #new-token: 223, #cached-token: 0, token usage: 0.99, #running-req: 88, #queue-req: 7, 
[2025-12-18 10:43:02] Prefill batch, #new-seq: 1, #new-token: 4502, #cached-token: 870, token usage: 0.97, #running-req: 86, #queue-req: 6, 
[2025-12-18 10:43:02] Prefill batch, #new-seq: 1, #new-token: 8192, #cached-token: 0, token usage: 0.97, #running-req: 85, #queue-req: 5, 
[2025-12-18 10:43:02] Prefill batch, #new-seq: 3, #new-token: 2723, #cached-token: 4, token usage: 0.98, #running-req: 85, #queue-req: 3, 
[2025-12-18 10:43:03] Prefill batch, #new-seq: 1, #new-token: 3827, #cached-token: 1, token usage: 0.98, #running-req: 86, #queue-req: 2, 
[2025-12-18 10:43:04] Prefill batch, #new-seq: 2, #new-token: 8192, #cached-token: 1, token usage: 0.94, #running-req: 86, #queue-req: 0, 
[2025-12-18 10:43:04] Prefill batch, #new-seq: 1, #new-token: 2040, #cached-token: 0, token usage: 0.96, #running-req: 87, #queue-req: 0, 
[2025-12-18 10:43:05] Decode batch, #running-req: 85, #token: 408575, token usage: 0.92, cuda graph: True, gen throughput (token/s): 587.05, #queue-req: 0, 
[2025-12-18 10:43:08] Decode batch, #running-req: 71, #token: 358228, token usage: 0.81, cuda graph: True, gen throughput (token/s): 1290.69, #queue-req: 0, 
[2025-12-18 10:43:10] Decode batch, #running-req: 57, #token: 290233, token usage: 0.66, cuda graph: True, gen throughput (token/s): 1168.64, #queue-req: 0, 
[2025-12-18 10:43:12] Decode batch, #running-req: 51, #token: 266660, token usage: 0.60, cuda graph: True, gen throughput (token/s): 1110.61, #queue-req: 0, 
[2025-12-18 10:43:14] Decode batch, #running-req: 47, #token: 244275, token usage: 0.55, cuda graph: True, gen throughput (token/s): 1063.54, #queue-req: 0, 
[2025-12-18 10:43:15] Decode batch, #running-req: 40, #token: 205312, token usage: 0.46, cuda graph: True, gen throughput (token/s): 1007.76, #queue-req: 0, 
[2025-12-18 10:43:17] Decode batch, #running-req: 38, #token: 199937, token usage: 0.45, cuda graph: True, gen throughput (token/s): 967.22, #queue-req: 0, 
[2025-12-18 10:43:18] Decode batch, #running-req: 36, #token: 190274, token usage: 0.43, cuda graph: True, gen throughput (token/s): 949.38, #queue-req: 0, 
[2025-12-18 10:43:20] Decode batch, #running-req: 32, #token: 174777, token usage: 0.40, cuda graph: True, gen throughput (token/s): 918.51, #queue-req: 0, 
[2025-12-18 10:43:21] Decode batch, #running-req: 23, #token: 134865, token usage: 0.31, cuda graph: True, gen throughput (token/s): 805.26, #queue-req: 0, 
[2025-12-18 10:43:23] Decode batch, #running-req: 19, #token: 109329, token usage: 0.25, cuda graph: True, gen throughput (token/s): 650.92, #queue-req: 0, 
[2025-12-18 10:43:24] Decode batch, #running-req: 18, #token: 100315, token usage: 0.23, cuda graph: True, gen throughput (token/s): 593.67, #queue-req: 0, 
[2025-12-18 10:43:25] Decode batch, #running-req: 17, #token: 91433, token usage: 0.21, cuda graph: True, gen throughput (token/s): 611.36, #queue-req: 0, 
[2025-12-18 10:43:26] Decode batch, #running-req: 13, #token: 64371, token usage: 0.15, cuda graph: True, gen throughput (token/s): 547.94, #queue-req: 0, 
[2025-12-18 10:43:27] Decode batch, #running-req: 10, #token: 49919, token usage: 0.11, cuda graph: True, gen throughput (token/s): 433.96, #queue-req: 0, 
[2025-12-18 10:43:28] Decode batch, #running-req: 8, #token: 33928, token usage: 0.08, cuda graph: True, gen throughput (token/s): 385.20, #queue-req: 0, 
[2025-12-18 10:43:29] Decode batch, #running-req: 5, #token: 20022, token usage: 0.05, cuda graph: True, gen throughput (token/s): 265.95, #queue-req: 0, 
[2025-12-18 10:43:30] Decode batch, #running-req: 4, #token: 15941, token usage: 0.04, cuda graph: True, gen throughput (token/s): 213.09, #queue-req: 0, 
[2025-12-18 10:43:31] Decode batch, #running-req: 2, #token: 9297, token usage: 0.02, cuda graph: True, gen throughput (token/s): 92.30, #queue-req: 0, 
[2025-12-18 10:43:31] Endpoint '/get_server_info' is deprecated and will be removed in a future version. Please use '/server_info' instead.
[2025-12-18 10:43:31] INFO:     127.0.0.1:45600 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-12-18 10:43:31] Endpoint '/get_server_info' is deprecated and will be removed in a future version. Please use '/server_info' instead.
[2025-12-18 10:43:31] INFO:     127.0.0.1:45604 - "GET /get_server_info HTTP/1.1" 200 OK
