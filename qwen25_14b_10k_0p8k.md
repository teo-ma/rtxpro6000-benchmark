# 测试记录：Qwen 2.5 14B（10K 输入 → 0.8K 输出）

## 测试设定

- 模型：Qwen 2.5 14B（本地路径：/mnt/data/models/Qwen2.5-14B-Instruct）
- 负载：输入 10000 tokens；输出 800 tokens
- 精度：FP8、FP4
- 并发：10 / 40 / 200
- GPU：RTX Pro 6000 BSE（96GB 显存）
- 推理引擎：vLLM 0.12.0

## 环境信息（每次测试前记录一次）

- 测试时间（时区）：2025-12-17 23:49:04 CST
- VM / 节点：
- GPU Driver：NVIDIA RTX Pro 6000 Blackwell DC-4-96Q, 98304 MiB, 580.105.08
- MIG：Enabled/Disabled；Profile：
- 关键参数：tensor_parallel_size=；gpu_memory_utilization=；其它：

## 结果汇总（填写）

### FP8

| 并发 | QPS | Prompt TPS (token/s) | Decode TPS (token/s) | TTFT (ms) | E2E (ms) | TPOT (ms) | 备注 |
|---:|---:|---:|---:|---:|---:|---:|---|
| 10 | 0.466 | 140084.873 | 37.437 | 74.819 | 21443.944 | 26.711 |  |
| 40 | 1.499 | 58136.265 | 30.187 | 173.982 | 26675.159 | 33.126 |  |
| 200 | 3.352 | 12524.882 | 26.817 | 11694.186 | 41591.683 | 37.372 |  |

### FP4

| 并发 | QPS | Prompt TPS (token/s) | Decode TPS (token/s) | TTFT (ms) | E2E (ms) | TPOT (ms) | 备注 |
|---:|---:|---:|---:|---:|---:|---:|---|
| 10 | 0.278 | 81622.426 | 22.341 | 126.953 | 35935.646 | 44.761 | bitsandbytes 4-bit |
| 40 | 0.878 | 42727.090 | 17.649 | 238.329 | 45567.801 | 56.662 | bitsandbytes 4-bit |
| 200 | 1.942 | 10408.976 | 15.525 | 19752.999 | 71348.606 | 64.495 | bitsandbytes 4-bit |

## 分析与结论（填写）

- 结论摘要：
- FP8 vs FP4：
- 并发扩展性（10→40→200）：
- 是否出现 OOM/排队/抖动：
- 下一步建议：

## 运行产物（可选）

- 日志路径：
- JSON 输出：
- 复现实验命令：
