# 测试记录：Qwen 2.5 32B（10K 输入 → 0.8K 输出）

## 测试设定

- 模型：Qwen 2.5 32B（HF：Qwen/Qwen2.5-32B-Instruct；本地路径：/mnt/data/models/Qwen2.5-32B-Instruct）
- 负载：输入 10000 tokens；输出 800 tokens
- 精度：FP8、FP4
- 并发：10 / 40 / 200
- GPU：RTX Pro 6000 BSE（96GB 显存）
- 推理引擎：vLLM 0.12.0

## 环境信息（每次测试前记录一次）

- 测试时间（时区）：2025-12-18 00:18:07 CST
- VM / 节点：
- GPU Driver：NVIDIA RTX Pro 6000 Blackwell DC-4-96Q, 98304 MiB, 580.105.08
- MIG：Enabled/Disabled；Profile：
- 关键参数：tensor_parallel_size=；gpu_memory_utilization=；其它：

## 结果汇总（填写）

### FP8

| 并发 | QPS | Prompt TPS (token/s) | Decode TPS (token/s) | TTFT (ms) | E2E (ms) | TPOT (ms) | 备注 |
|---:|---:|---:|---:|---:|---:|---:|---|
| 10 | 0.259 | 102448.224 | 20.807 | 104.436 | 38552.727 | 48.060 |  |
| 40 | 0.917 | 58978.072 | 18.429 | 182.293 | 43592.658 | 54.263 |  |
| 200 | 2.073 | 9408.668 | 16.568 | 18706.761 | 67076.900 | 60.463 |  |

### FP4

| 并发 | QPS | Prompt TPS (token/s) | Decode TPS (token/s) | TTFT (ms) | E2E (ms) | TPOT (ms) | 备注 |
|---:|---:|---:|---:|---:|---:|---:|---|
| 10 |  |  |  |  |  |  |  |
| 40 |  |  |  |  |  |  |  |
| 200 |  |  |  |  |  |  |  |

## 分析与结论（填写）

- 结论摘要：
- FP8 vs FP4：
- 并发扩展性（10→40→200）：
- 是否出现 OOM/排队/抖动：
- 下一步建议：

## 运行产物（可选）

- 日志路径：
- JSON 输出：
- 复现实验命令：
